# IBM Attrition Prediction â€” ML Aplicado

Modelo de predicciÃ³n de **attrition** (renuncia de empleados por desgaste) con el dataset sintÃ©tico de IBM. Este repo contiene el desarrollo del proyecto, desde el EDA, la preparaciÃ³n de datos, pipelines de entrenamiento y resultados.

---

## ğŸ—‚ï¸ Estructura del repositorio

```
ml-aplicado-attrition-prediction-IBM/
â”œâ”€ ENTREGA 1/         # Notebooks y artefactos de la entrega (EDA, preparaciÃ³n, modelado)
â”œâ”€ ENTREGA 2/         # Notebooks y artefactos de la entrega (FE, tuning y umbrales)
â”œâ”€ .gitignore
â””â”€ README.md
```

> Nota: Estructura observada en la rama `main`. Los notebooks de trabajo se encuentran en **ENTREGA XX/procesamiento**.

---

## ğŸ“¦ Dataset - Contexto

La rotaciÃ³n de empleados es un desafÃ­o comÃºn en todas las empresas, ya que genera costos importantes relacionados con la interrupciÃ³n de procesos, la contrataciÃ³n y la capacitaciÃ³n de nuevo personal. Para enfrentar este problema, los modelos de clasificaciÃ³n pueden ayudar a predecir quÃ© empleados tienen mayor probabilidad de renunciar, lo que permite a Recursos Humanos intervenir a tiempo. Sin embargo, el Ã©xito no depende solo del modelo, sino tambiÃ©n del factor humano: hablar con el empleado, entender su situaciÃ³n y actuar sobre aspectos que se pueden controlar.

El dataset de IBM utilizado para este anÃ¡lisis es limitado en tamaÃ±o, lo que implica que los modelos solo ofrecen una mejora moderada frente al azar. Aun asÃ­, entender y reducir la rotaciÃ³n, ademÃ¡s de prepararse para los casos inevitables, puede mejorar notablemente las operaciones de una organizaciÃ³n. Con un conjunto de datos mÃ¡s grande, serÃ­a posible segmentar empleados en categorÃ­as de riesgo y obtener insights mÃ¡s profundos sobre las causas de la rotaciÃ³n, generando aprendizajes mÃ¡s valiosos que los que se logran solo con entrevistas.

## ğŸ“¦ Dataset â€” Data Card

**Nombre:** IBM HR Analytics â€“ Employee Attrition & Performance  
**Origen:** conjunto **ficticio/sintÃ©tico** creado por IBM para anÃ¡lisis de rotaciÃ³n.  
**Tarea:** **clasificaciÃ³n binaria** (`Attrition`: Yes/No).  
**Usos tÃ­picos:** detecciÃ³n de riesgo de renuncia, priorizaciÃ³n de acciones de *retenciÃ³n*, anÃ¡lisis de factores asociados.

**UbicaciÃ³n:** https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset/data


### ComposiciÃ³n
- **TamaÃ±o:** **1,470** filas Ã— **35** columnas.  
- **Tipos de variables:**
  - **NumÃ©ricas** (p. ej., `Age`, `MonthlyIncome`, `DistanceFromHome`).
  - **CategÃ³ricas nominales** (`Department`, `JobRole`, `Gender`, `BusinessTravel`, `MaritalStatus`).
  - **CategÃ³ricas ordinales** codificadas como enteros: `Education` (1â€“5), `Job/Environment/RelationshipSatisfaction` (1â€“4), `JobInvolvement` (1â€“4), `WorkLifeBalance` (1â€“4), `PerformanceRating` (1â€“4), `StockOptionLevel` (0â€“3).
- **Columnas constantes / poca utilidad:** `EmployeeCount`, `StandardHours` (constantes) y `Over18` (casi siempre â€œYesâ€).
- **Identificador:** `EmployeeNumber` (ID Ãºnico) â†’ **no** usar como predictor (solo para trazabilidad).

### Calidad de datos
- **Nulos:** dataset consultado desde Kaggle **sin valores faltantes**.  
- **Desbalance:** la clase `Attrition=Yes` es minoritaria (desbalance moderado del 16%).  
- **Ordinalidad:** tratar escalas 1â€“4/1â€“5 como **ordinales** cuando el modelo lo permita.


## âš™ï¸ CÃ³mo ejecutar

![âš ï¸ IMPORTANTE](https://img.shields.io/badge/%E2%9A%A0%EF%B8%8F-WARNING-red?style=for-the-badge) 

Para una correcta ejecuciÃ³n en Colab, se debe usar el runtime 2025.07 que habilita dependencias internas requeridas por la librerÃ­a `pycaret`

1. El notebook fue ejecutado en Colab, se sugiere validar su ejecuciÃ³n tambiÃ©n en Colab
2. Cargar directamente el notebook, el archivo de scripts utils.py con mÃ©todos para aplicar EDA y el dataset local dataset_ibm.csv. Si se desea ejecutar solo el tuning, se debe cargar el dataset local dataset_ibm_sin_outliers.csv, resultante de la primera etapa de modelaciÃ³n.
3. Entrega 1: Ejecutar el flujo: **EDA â†’ preparaciÃ³n â†’ baseline** (Opcional si se remite directamente al tuning)
4. Entrega 2: Ejecutar el flujo: **FE â†’ pipelines â†’ tuning â†’ anÃ¡lisis de umbrales**

---

## ğŸ“ˆ Resultados preliminares

### Entrega 1:

**Modelo baseline:** RegresiÃ³n LogÃ­stica  
**MÃ©tricas(conjunto de test):** Accuracy **89.4%** Â· AUC **90.7%** Â· Recall **57.9%** Â· Precision **64.7%** Â· F1 **61.1%** Â· Kappa **55.5%** 

**InterpretaciÃ³n preliminar:** buen equilibrio general, con margen para aumentar **recall** de la clase positiva mediante **ajuste de umbral**, `class_weight` o **calibraciÃ³n**, y oportunidades de mejora mediante la implementaciÃ³n de **ingenierÃ­a de caracterÃ­sticas**

### Entrega 2:
**Modelo candidato:** XGBoost  
**MÃ©tricas(conjunto de test):** Accuracy **80.3%** Â· AUC **88.6%** Â· Recall **76.1%** Â· Precision **68.4%** Â· F1 **70.6%** Â· Kappa **42.1%** 

**InterpretaciÃ³n preliminar:** se mantiene el equilibrio general, evidenciandose mejorÃ­a en el recall y f1 score, generando mayor confianza en el modelo para apoyar la retenciÃ³n de empleados

---

## ğŸš€ PrÃ³ximos pasos

Entrega 1 (HECHO):
- Ajuste de **umbral** y **calibraciÃ³n** (Platt/IsotÃ³nica) para mejorar recall manteniendo precisiÃ³n.  
- Generar **Interacciones/transformaciones** Ãºtiles en la fase de ingenierÃ­a de caracterÃ­sticas
- Comparar con **boosting** (LightGBM/XGBoost) manteniendo la logÃ­stica como referencia.  
- Reporte de mÃ©tricas por grupos poblacionales y **entrenamiento robusto**

Entrega 2:
- CalibraciÃ³n de modelo candidato
- Importancia de caracterÃ­sticas
- Conclusiones y despliegue

---

## ğŸ¤ CrÃ©ditos

Este proyecto estÃ¡ siendo desarrollado por:
- ### Andrea Paola Alzate Ramirez
- ### Gustavo Adolfo Jerez Tous
